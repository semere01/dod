{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from PIL import Image\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import mahotas as mt\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from sklearn.tree import export_graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(image):\n",
    "    textures = mt.features.haralick(image)\n",
    "    ht_mean = textures.mean(axis=0)\n",
    "    return ht_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fd_histogram(image, mask=None):\n",
    "    # convert the image to HSV color-shape\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    # compute the color histogram\n",
    "    hist = cv2.calcHist([image], [0, 1, 2], None, [bins, bins, bins], [0, 256, 0, 256, 0, 256])\n",
    "    # normalize the histogram\n",
    "    cv2.normalize(hist, hist)\n",
    "    #return the histogram\n",
    "    return hist.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fd_hu_moments(image):\n",
    "    feature = cv2.HuMoments(cv2.moments(image)).flatten()\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n"
     ]
    }
   ],
   "source": [
    "# grab all image paths in the input dataset directory, then initialize\n",
    "# our list of images and corresponding class labels\n",
    "print(\"[INFO] loading images...\")\n",
    "imagePaths = sorted(list(paths.list_images(\"dataset\")))\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(imagePaths)\n",
    "global_feature=[]\n",
    "data = []\n",
    "labels = []\n",
    "IMAGE_DIMS = (50 ,50, 1)\n",
    "bins = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the input images\n",
    "for imagePath in imagePaths:\n",
    "    # load the image, pre-process it, and store it in the data list\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.resize(image, (IMAGE_DIMS[1], IMAGE_DIMS[0]))\n",
    "    fv_histogram = fd_histogram(image)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    fv_hu_moments = fd_hu_moments(image)\n",
    "    features = extract_features(image)\n",
    "    global_feature = np.hstack([fv_histogram, features, fv_hu_moments])\n",
    "    data.append(global_feature)\n",
    "    l = label = imagePath.split(os.path.sep)[-2]\n",
    "    labels.append(l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the dictionary of models our script can use, where the key \n",
    "# to the dictionary is the name of the model (supplied via command\n",
    "# line argument) and the value is the model itself\n",
    "models = {\n",
    "    \"knn\": KNeighborsClassifier(n_neighbors=1),\n",
    "    \"naive_bayes\": GaussianNB(),\n",
    "    \"logit\": LogisticRegression(solver=\"1bfgs\", multi_class=\"auto\"),\n",
    "    \"svm\":SVC(kernel=\"poly\", degree=2),\n",
    "    \"decision_tree\": DecisionTreeClassifier(),\n",
    "    \"random_forest\": RandomForestClassifier(n_estimators=100),\n",
    "    \"mlp\": MLPClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition the data into training and testing splits, using 75%\n",
    "# of the data for training and the remaining 25% for testing\n",
    "print(\"[INFO] constructing training/testing split...\")\n",
    "(trainData, testData, trainLabels, testLabels) = train_test_split(data, labels, test_size = 0.25, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
